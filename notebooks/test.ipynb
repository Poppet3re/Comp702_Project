{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/R100/R100f_big5.jpg',cv2.IMREAD_COLOR)\n",
    "img_blur = cv2.GaussianBlur(img, (5,5), 0)\n",
    "img_gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY)\n",
    "img_eq = cv2.equalizeHist(img_gray)\n",
    "img_neg = cv2.bitwise_not(img_eq)\n",
    "img_resized = cv2.resize(img_neg, (574,265))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(img_resized, 100, 200)\n",
    "_, thresh = cv2.threshold(img_resized, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "erosion = cv2.erode(dilation, kernel, iterations=1)\n",
    "\n",
    "contours, _ = cv2.findContours(erosion, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "img_contours = cv2.drawContours(img_resized, contours, -1, (0,255,0), 3)\n",
    "\n",
    "#display images\n",
    "cv2.imshow('Edges Image', edges)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orb feature extraction on edges\n",
    "orb = cv2.ORB_create()\n",
    "keypoints, descriptors = orb.detectAndCompute(edges, None)\n",
    "# show image with keypoints and descriptors\n",
    "img_keypoints = cv2.drawKeypoints(edges, keypoints, None)\n",
    "cv2.imshow('ORB keypoints', img_keypoints)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print grayed image\n",
    "cv2.imshow('gray', img_resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for the input image is: R100\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "classes = ['R10', 'R20', 'R50', 'R100', 'R200']\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "def preprocess_and_extract_features(img_path, max_features=500):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    img_blur = cv2.GaussianBlur(img, (5,5), 0)\n",
    "    img_gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY)\n",
    "    img_eq = cv2.equalizeHist(img_gray)\n",
    "    img_neg = cv2.bitwise_not(img_eq)\n",
    "    img_resized = cv2.resize(img_neg, (574,265))\n",
    "    edges = cv2.Canny(img_resized, 100, 200)\n",
    "\n",
    "    keypoints, descriptors = orb.detectAndCompute(edges, None)\n",
    "    if descriptors is None:\n",
    "        descriptors = np.zeros((max_features, orb.descriptorSize()), dtype=np.uint8)\n",
    "    else:\n",
    "        # Pad or truncate descriptors to ensure uniform length\n",
    "        if len(descriptors) < max_features:\n",
    "            pad_length = max_features - len(descriptors)\n",
    "            descriptors = np.pad(descriptors, ((0, pad_length), (0, 0)), 'constant')\n",
    "        elif len(descriptors) > max_features:\n",
    "            descriptors = descriptors[:max_features]\n",
    "    return descriptors\n",
    "\n",
    "for label in classes:\n",
    "    class_dir = os.path.join(data_dir, label)\n",
    "    for filename in os.listdir(class_dir):\n",
    "        img_path = os.path.join(class_dir, filename)\n",
    "        descriptors = preprocess_and_extract_features(img_path)\n",
    "\n",
    "        for descriptor in descriptors:\n",
    "            features.append(descriptor.ravel())\n",
    "            labels.append(label)\n",
    "\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Manual KNN Classifier\n",
    "def knn_classify(X_train, y_train, x_test, k=3):\n",
    "    distances = []\n",
    "    for i in range(len(X_train)):\n",
    "        dist = distance.euclidean(X_train[i], x_test)\n",
    "        distances.append((dist, y_train[i]))\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    neighbors = distances[:k]\n",
    "    class_votes = {}\n",
    "    for neighbor in neighbors:\n",
    "        label = neighbor[1]\n",
    "        class_votes[label] = class_votes.get(label, 0) + 1\n",
    "    sorted_votes = sorted(class_votes.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_votes[0][0]\n",
    "\n",
    "# Function to classify a new input image\n",
    "def classify_new_image(img_path, X_train, y_train, k=3):\n",
    "    descriptors = preprocess_and_extract_features(img_path)\n",
    "    # Flatten descriptors to match training data structure\n",
    "    descriptors = descriptors.reshape(-1, orb.descriptorSize())\n",
    "    predictions = []\n",
    "    for descriptor in descriptors:\n",
    "        prediction = knn_classify(X_train, y_train, descriptor, k)\n",
    "        predictions.append(prediction)\n",
    "    return max(set(predictions), key=predictions.count)\n",
    "\n",
    "# Test with a new input image\n",
    "test_img_path = 'test200.jpg'\n",
    "prediction = classify_new_image(test_img_path, features, labels)\n",
    "print(f'The predicted class for the input image is: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for the input image is: R200\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Define paths and classes\n",
    "data_dir = 'data'\n",
    "classes = ['R10', 'R20', 'R50', 'R100', 'R200']\n",
    "\n",
    "# Initialize ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Initialize lists to hold features and labels\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img_blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    img_gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY)\n",
    "    img_eq = cv2.equalizeHist(img_gray)\n",
    "    img_neg = cv2.bitwise_not(img_eq)\n",
    "    img_resized = cv2.resize(img_neg, (574, 265))\n",
    "    edges = cv2.Canny(img_resized, 100, 200)\n",
    "    return edges\n",
    "\n",
    "def extract_features(img, max_features=500):\n",
    "    keypoints, descriptors = orb.detectAndCompute(img, None)\n",
    "    if descriptors is None:\n",
    "        descriptors = np.zeros((max_features, orb.descriptorSize()), dtype=np.uint8)\n",
    "    else:\n",
    "        # Pad or truncate descriptors to ensure uniform length\n",
    "        if len(descriptors) < max_features:\n",
    "            pad_length = max_features - len(descriptors)\n",
    "            descriptors = np.pad(descriptors, ((0, pad_length), (0, 0)), 'constant')\n",
    "        elif len(descriptors) > max_features:\n",
    "            descriptors = descriptors[:max_features]\n",
    "    return descriptors\n",
    "\n",
    "# Process all images and extract features\n",
    "for label in classes:\n",
    "    class_dir = os.path.join(data_dir, label)\n",
    "    for filename in os.listdir(class_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            img_path = os.path.join(class_dir, filename)\n",
    "            preprocessed_img = preprocess_image(img_path)\n",
    "            descriptors = extract_features(preprocessed_img)\n",
    "            \n",
    "            for descriptor in descriptors:\n",
    "                features.append(descriptor.ravel())\n",
    "                labels.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Manual KNN Classifier\n",
    "def knn_classify(X_train, y_train, x_test, k=5):\n",
    "    distances = []\n",
    "    for i in range(len(X_train)):\n",
    "        dist = distance.euclidean(X_train[i], x_test)\n",
    "        distances.append((dist, y_train[i]))\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    neighbors = distances[:k]\n",
    "    class_votes = {}\n",
    "    for neighbor in neighbors:\n",
    "        label = neighbor[1]\n",
    "        class_votes[label] = class_votes.get(label, 0) + 1\n",
    "    sorted_votes = sorted(class_votes.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_votes[0][0]\n",
    "\n",
    "# Function to classify a new input image\n",
    "def classify_new_image(img_path, X_train, y_train, k=5):\n",
    "    preprocessed_img = preprocess_image(img_path)\n",
    "    descriptors = extract_features(preprocessed_img)\n",
    "    # Flatten descriptors to match training data structure\n",
    "    descriptors = descriptors.reshape(-1, orb.descriptorSize())\n",
    "    predictions = []\n",
    "    for descriptor in descriptors:\n",
    "        prediction = knn_classify(X_train, y_train, descriptor, k)\n",
    "        predictions.append(prediction)\n",
    "    return max(set(predictions), key=predictions.count)\n",
    "\n",
    "# Test with a new input image\n",
    "test_img_path = 'test50.jpg'\n",
    "prediction = classify_new_image(test_img_path, features, labels)\n",
    "print(f'The predicted class for the input image is: {prediction}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
