{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-image --quiet\n",
    "%pip install numpy --quiet\n",
    "%pip install matplotlib --quiet\n",
    "%pip install scipy --quiet\n",
    "%pip install opencv-python --quiet\n",
    "%pip install opencv-python-headless --quiet\n",
    "%pip install opencv-contrib-python --quiet\n",
    "%pip install scikit-learn --quiet\n",
    "%pip install seaborn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from skimage import filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "ORB_FEATURES = 1000 # Number of features to extract\n",
    "KNN = 3 # Number of neighbors to use in KNN\n",
    "\n",
    "ADD_VARIATION = True # Add variations to the dataset\n",
    "ADD_ROTATION = True # Add rotated images to the dataset\n",
    "ADD_FLIP = True # Add flipped images to the dataset\n",
    "ADD_SCALE = True # Add scaled images to the dataset\n",
    "\n",
    "data_train_dir = 'data/train' # Directory containing training data\n",
    "\n",
    "# Directory containing handpicked examples that can stand as outliers\n",
    "# These are used to do further testing on the model,\n",
    "# besides the standard train/test split\n",
    "data_test_dir = 'data/test' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images and keep the folder name as the label\n",
    "def load_images(folder, n=None):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(folder):\n",
    "        for filename in os.listdir(os.path.join(folder, label)):\n",
    "            img = cv2.imread(os.path.join(folder, label, filename))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "            \n",
    "            if n is not None and len(images) >= n:\n",
    "                break\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_images(data_train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that there are no duplicates // count\n",
    "for i in range(len(images)):\n",
    "    for j in range(i+1, len(images)):\n",
    "        if np.array_equal(images[i], images[j]):\n",
    "            print(i, j)\n",
    "            print(labels[i], labels[j])\n",
    "            print(np.array_equal(images[i], images[j]))\n",
    "            print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to display images\n",
    "def display( l_images, r_images, l_labels,r_labels=None, display_images=None):\n",
    "    if r_labels is None:\n",
    "        r_labels = l_labels\n",
    "    if display_images is None:\n",
    "        display_images = range(len(l_images))\n",
    "    for i in display_images:\n",
    "        f, axarr = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axarr[0].imshow(cv2.cvtColor(l_images[i], cv2.COLOR_BGR2RGB))\n",
    "        axarr[0].set_title(str(i+1) + ': ' + l_labels[i])\n",
    "        axarr[0].axis('off')\n",
    "        axarr[1].imshow(cv2.cvtColor(r_images[i], cv2.COLOR_BGR2RGB))\n",
    "        axarr[1].set_title(str(i+1) + ': ' + r_labels[i] + ' (processed)')\n",
    "        axarr[1].axis('off')\n",
    "        plt.show()\n",
    "display(images, images, labels, labels, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add variations to the dataset\n",
    "def variants(img):\n",
    "    if not ADD_VARIATION:\n",
    "        return [img]\n",
    "    variants = []\n",
    "    angles = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_180, cv2.ROTATE_90_COUNTERCLOCKWISE]\n",
    "    flips = [0, 1]\n",
    "    diagonal_angles = [45, 135, 225, 315]\n",
    "    for angle in angles:\n",
    "        var = cv2.rotate(img, angle)\n",
    "        variants.append(var)\n",
    "        for flip in flips:\n",
    "            var = cv2.flip(var, flip)\n",
    "            variants.append(var)\n",
    "    \n",
    "    # add rotated images\n",
    "    for angle in diagonal_angles:\n",
    "        M = cv2.getRotationMatrix2D((img.shape[1]//2, img.shape[0]//2), angle, 1)\n",
    "        var = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), borderValue=(255, 255, 255))\n",
    "        variants.append(var)\n",
    "        for flip in flips:\n",
    "            var = cv2.flip(var, flip)\n",
    "            variants.append(var)\n",
    "    \n",
    "    # rm duplicates\n",
    "    new_variants = []\n",
    "    for i in range(len(variants)):\n",
    "        for j in range(0, len(new_variants)):\n",
    "            if np.array_equal(variants[i], new_variants[j]):\n",
    "                break\n",
    "        else:\n",
    "            new_variants.append(variants[i])\n",
    "    return new_variants\n",
    "\n",
    "\n",
    "\n",
    "variant_images = []\n",
    "variant_labels = []\n",
    "for i in range(len(images)):\n",
    "    for img in variants(images[i]):\n",
    "        variant_images.append(img)\n",
    "        variant_labels.append(labels[i])\n",
    "\n",
    "# plot the first image and its variants in a small grid\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(20):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(cv2.cvtColor(variant_images[i], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(variant_labels[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Preprocess the images\n",
    "def preprocess(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.normalize(img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    return img\n",
    "\n",
    "preprocessed_images = [preprocess(img) for img in variant_images]\n",
    "\n",
    "display(variant_images, preprocessed_images, variant_labels, variant_labels, [0, 426, 400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the images\n",
    "def contour_segmentation(img):\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    # find the contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # find the largest contour\n",
    "    max_area = 0\n",
    "    max_contour = None\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            max_contour = contour\n",
    "    # find the bounding rectangle\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "    # crop the image  into rect\n",
    "    img = img[y:y+h, x:x+w]\n",
    "    # img = img[y:y+(h if h < w else w), x:x+(h if h < w else w)]\n",
    "    return img\n",
    "\n",
    "def grab_cut(img):\n",
    "\n",
    "    # remove alpha channel\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    # create a mask\n",
    "    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "\n",
    "    # define the background and foreground models\n",
    "    bgdModel = np.zeros((1, 65), np.float64)\n",
    "\n",
    "    fgdModel = np.zeros((1, 65), np.float64)\n",
    "\n",
    "    # define the rectangle\n",
    "    perc = 0.1\n",
    "    padX = int(perc * img.shape[0])\n",
    "    padY = int(perc * img.shape[1])\n",
    "\n",
    "    rect = (padX, padY, img.shape[1] - 2 * padX, img.shape[0] - 2 * padY)\n",
    "    # apply grabcut\n",
    "    cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "    # create a mask with the probable foreground\n",
    "    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "    # apply the mask to the image\n",
    "    img = img * mask2[:, :, np.newaxis]\n",
    "\n",
    "    return img\n",
    "\n",
    "aligned_images = [contour_segmentation(img) for img in preprocessed_images]\n",
    "# aligned_images = [grab_cut(img) for img in preprocessed_images]\n",
    "display(preprocessed_images, aligned_images, variant_labels, variant_labels, [0, 426, 400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orientation so that the longest side is the width\n",
    "def orientation(img):\n",
    "    # return img if img.shape[0] < img.shape[1] else cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    return img\n",
    "\n",
    "oriented = [orientation(img) for img in aligned_images]\n",
    "\n",
    "display(aligned_images, oriented, variant_labels, variant_labels, [0, 426, 400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "def extract_features_orb(img, n_features=ORB_FEATURES):\n",
    "    orb = cv2.ORB_create(n_features)\n",
    "    keypoints, descriptors = orb.detectAndCompute(img, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def extract_features_sift(img):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def extract_features_harris(img):\n",
    "    # remove alpha channel\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    dst = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
    "    dst = cv2.dilate(dst, None)\n",
    "    ret, dst = cv2.threshold(dst, 0.01 * dst.max(), 255, 0)\n",
    "    dst = np.uint8(dst)\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv2.cornerSubPix(gray, np.float32(centroids), (5, 5), (-1, -1), criteria)\n",
    "    return corners\n",
    "\n",
    "def extract_features_hog(img):\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    h = hog.compute(img)\n",
    "    return h\n",
    "\n",
    "## ------------------------------------------------------------------------------------------------\n",
    "## CHANGE THIS TO USE THE FEATURE EXTRACTION METHOD YOU WANT\n",
    "# keypoints, descriptors = zip(*[extract_features_orb(img) for img in oriented])\n",
    "# keypoints, descriptors = zip(*[extract_features_sift(img) for img in oriented])\n",
    "descriptors = [extract_features_harris(img) for img in oriented]\n",
    "# keypoints = [extract_features_hog(img) for img in oriented]\n",
    "## ------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# check if any features were found\n",
    "for i in range(len(descriptors)):\n",
    "    if descriptors[i] is None:\n",
    "        print('No features found for image', i)\n",
    "        plt.imshow(cv2.cvtColor(aligned_images[i], cv2.COLOR_BGR2RGB))\n",
    "        plt.title('No features found')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "print('Number of descriptors:',len(descriptors))\n",
    "print('All shapes:', [d.shape for d in descriptors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display keypoints\n",
    "def display_keypoints(img, keypoints):\n",
    "    img = cv2.drawKeypoints(img, keypoints, None)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "display_keypoints(oriented[0], keypoints[0])\n",
    "display_keypoints(oriented[25], keypoints[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=1000, random_state=42)\n",
    "kmeans.fit(np.vstack(descriptors))\n",
    "\n",
    "# save the kmeans model\n",
    "import pickle\n",
    "with open('kmeans.pkl', 'wb') as f:\n",
    "    pickle.dump(kmeans, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of visual words\n",
    "def bag_of_words(descriptors, kmeans):\n",
    "    histogram = np.zeros(kmeans.n_clusters)\n",
    "    if descriptors is not None:\n",
    "        clusters = kmeans.predict(descriptors)\n",
    "        for cluster in clusters:\n",
    "            histogram[cluster] += 1\n",
    "    return histogram\n",
    "\n",
    "bovw = np.array([bag_of_words(d, kmeans) for d in descriptors])\n",
    "bovw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bovw, variant_labels, test_size=0.2, random_state=42, stratify=variant_labels)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=rf.classes_, yticklabels=rf.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# save the model\n",
    "import joblib\n",
    "joblib.dump(rf, 'rf.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', C=1, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=svm.classes_, yticklabels=svm.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# save the model\n",
    "joblib.dump(svm, 'svc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=knn.classes_, yticklabels=knn.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# save the model\n",
    "joblib.dump(knn, 'knn.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional more complex testing\n",
    "# some very specific examples that are difficult to classify\n",
    "test_images, test_labels = load_images(data_test_dir)\n",
    "print(test_labels)\n",
    "preprocessed_test_images = [preprocess(img) for img in test_images]\n",
    "aligned_test_images = [contour_segmentation(img) for img in preprocessed_test_images]\n",
    "oriented_test_images = [orientation(img) for img in aligned_test_images]\n",
    "# keypoints_test, descriptors_test = zip(*[extract_features_orb(img) for img in oriented_test_images])\n",
    "# keypoints_test, descriptors_test = zip(*[extract_features_sift(img) for img in oriented_test_images])\n",
    "descriptors_test = [extract_features_harris(img) for img in oriented_test_images]\n",
    "bovw_test = np.array([bag_of_words(d, kmeans) for d in descriptors_test])\n",
    "y_pred = rf.predict(bovw_test)\n",
    "print('Accuracy:', accuracy_score(test_labels, y_pred))\n",
    "\n",
    "y_pred = svm.predict(bovw_test)\n",
    "print('Accuracy:', accuracy_score(test_labels, y_pred))\n",
    "\n",
    "y_pred = knn.predict(bovw_test)\n",
    "print('Accuracy:', accuracy_score(test_labels, y_pred))\n",
    "\n",
    "# print oriented_test_images\n",
    "display(preprocessed_test_images, oriented_test_images, test_labels, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
